package performance

import (
	"bytes"
	"context"
	"encoding/json"
	"fmt"
	"io"
	"log/slog"
	"net/http"
	"net/http/httptest"
	"path/filepath"
	"runtime"
	"sync"
	"sync/atomic"
	"testing"
	"time"

	"github.com/go-chi/chi/v5"
	"github.com/go-chi/chi/v5/middleware"
	"github.com/stretchr/testify/assert"
	"github.com/stretchr/testify/require"

	handlers "isxcli/internal/transport/http"
	"isxcli/internal/license"
	"isxcli/internal/services"
)

// Performance test configuration
const (
	BenchmarkDuration     = 10 * time.Second
	LoadTestDuration      = 30 * time.Second
	MaxLatency           = 100 * time.Millisecond
	TargetThroughput     = 1000 // requests per second
)

var ConcurrencyLevels = []int{1, 10, 50, 100, 200}

// PerformanceTestSuite provides performance testing for license operations
type PerformanceTestSuite struct {
	tempDir     string
	licenseFile string
	manager     *license.Manager
	service     services.LicenseService
	handler     *handlers.LicenseHandler
	server      *httptest.Server
	logger      *slog.Logger
}

func setupPerformanceTest(t *testing.T) *PerformanceTestSuite {
	suite := &PerformanceTestSuite{
		tempDir:     t.TempDir(),
		logger:      slog.New(slog.NewTextHandler(io.Discard, nil)),
	}
	
	suite.licenseFile = filepath.Join(suite.tempDir, "perf_test_license.dat")
	
	var err error
	suite.manager, err = license.NewManager(suite.licenseFile)
	require.NoError(t, err)
	
	suite.service = services.NewLicenseService(suite.manager, suite.logger)
	suite.handler = handlers.NewLicenseHandler(suite.service, suite.logger)
	
	// Setup HTTP server
	router := chi.NewRouter()
	router.Use(middleware.RequestID)
	router.Use(middleware.Timeout(30 * time.Second))
	router.Mount("/api/license", suite.handler.Routes())
	
	suite.server = httptest.NewServer(router)
	
	// Setup a valid license for testing
	// Note: testLicense variable is not used, removing it
	
	// Create valid license state for performance testing
	err = suite.manager.ActivateLicense("PERF-TEST-KEY")
	if err != nil {
		// Expected to fail for test key, continue with tests
		t.Logf("License activation failed as expected: %v", err)
	}
	
	return suite
}

func (suite *PerformanceTestSuite) teardown() {
	if suite.server != nil {
		suite.server.Close()
	}
	if suite.manager != nil {
		suite.manager.Close()
	}
}

// setupBenchmark creates a test suite for benchmarks
func setupBenchmark(b *testing.B) *PerformanceTestSuite {
	suite := &PerformanceTestSuite{
		tempDir:     b.TempDir(),
	}
	
	logger := slog.Default()
	
	// Create license manager
	suite.manager, _ = license.NewManager(filepath.Join(suite.tempDir, "license.dat"))
	
	// Create services
	suite.service = services.NewLicenseService(suite.manager, logger)
	
	// Create handler
	suite.handler = handlers.NewLicenseHandler(suite.service, logger)
	
	// Setup test server
	router := chi.NewRouter()
	router.Use(middleware.RequestID)
	router.Mount("/api/license", suite.handler.Routes())
	
	suite.server = httptest.NewServer(router)
	
	// Create valid license state for performance testing
	err := suite.manager.ActivateLicense("PERF-TEST-KEY")
	if err != nil {
		// Expected to fail for test key, continue with tests
		b.Logf("License activation failed as expected: %v", err)
	}
	
	return suite
}

// BenchmarkLicenseStatusCheck benchmarks license status checking
func BenchmarkLicenseStatusCheck(b *testing.B) {
	suite := setupBenchmark(b)
	defer suite.teardown()
	
	b.ResetTimer()
	b.ReportAllocs()
	
	b.RunParallel(func(pb *testing.PB) {
		for pb.Next() {
			resp, err := http.Get(suite.server.URL + "/api/license/status")
			if err != nil {
				b.Fatalf("Request failed: %v", err)
			}
			resp.Body.Close()
			
			if resp.StatusCode != http.StatusOK {
				b.Fatalf("Expected status 200, got %d", resp.StatusCode)
			}
		}
	})
}

// BenchmarkLicenseValidation benchmarks license validation operations
func BenchmarkLicenseValidation(b *testing.B) {
	suite := setupBenchmark(b)
	defer suite.teardown()
	
	ctx := context.Background()
	
	b.ResetTimer()
	b.ReportAllocs()
	
	b.RunParallel(func(pb *testing.PB) {
		for pb.Next() {
			_, err := suite.service.ValidateWithContext(ctx)
			if err != nil {
				b.Logf("Validation error (may be expected): %v", err)
			}
		}
	})
}

// BenchmarkDetailedStatus benchmarks detailed status operations
func BenchmarkDetailedStatus(b *testing.B) {
	suite := setupBenchmark(b)
	defer suite.teardown()
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		resp, err := http.Get(suite.server.URL + "/api/license/detailed")
		if err != nil {
			b.Fatalf("Request failed: %v", err)
		}
		resp.Body.Close()
		
		if resp.StatusCode != http.StatusOK {
			b.Fatalf("Expected status 200, got %d", resp.StatusCode)
		}
	}
}

// BenchmarkLicenseActivation benchmarks license activation requests
func BenchmarkLicenseActivation(b *testing.B) {
	suite := setupBenchmark(b)
	defer suite.teardown()
	
	activationRequest := map[string]string{
		"license_key": "ISX1Y-BENCH-12345-MARKS-67890",
		"email":       "benchmark@test.com",
	}
	
	requestBody, _ := json.Marshal(activationRequest)
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		resp, err := http.Post(
			suite.server.URL+"/api/license/activate",
			"application/json",
			bytes.NewReader(requestBody),
		)
		if err != nil {
			b.Fatalf("Request failed: %v", err)
		}
		resp.Body.Close()
		
		// Accept various status codes as activation may fail for test keys
		if resp.StatusCode < 200 || resp.StatusCode >= 500 {
			b.Fatalf("Unexpected status code: %d", resp.StatusCode)
		}
	}
}

// TestLoadLicenseStatusEndpoint tests load performance of status endpoint
func TestLoadLicenseStatusEndpoint(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping load test in short mode")
	}
	
	suite := setupPerformanceTest(t)
	defer suite.teardown()
	
	for _, concurrency := range ConcurrencyLevels {
		t.Run(fmt.Sprintf("concurrency_%d", concurrency), func(t *testing.T) {
			results := runLoadTest(t, suite.server.URL+"/api/license/status", "GET", nil, concurrency, LoadTestDuration)
			
			t.Logf("Concurrency %d - Requests: %d, Success: %d, Errors: %d", 
				concurrency, results.TotalRequests, results.SuccessfulRequests, results.ErrorCount)
			t.Logf("Throughput: %.2f req/s, Avg Latency: %v, P95 Latency: %v", 
				results.Throughput, results.AverageLatency, results.P95Latency)
			
			// Performance assertions
			assert.Greater(t, results.SuccessfulRequests, int64(0), "Should have successful requests")
			assert.Less(t, results.ErrorCount, results.TotalRequests/10, "Error rate should be less than 10%")
			assert.Less(t, results.AverageLatency, MaxLatency, "Average latency should be acceptable")
			
			// Log memory usage
			var m runtime.MemStats
			runtime.GC()
			runtime.ReadMemStats(&m)
			t.Logf("Memory usage - Alloc: %d KB, Sys: %d KB", m.Alloc/1024, m.Sys/1024)
		})
	}
}

// TestLoadLicenseActivationEndpoint tests load performance of activation endpoint
func TestLoadLicenseActivationEndpoint(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping load test in short mode")
	}
	
	suite := setupPerformanceTest(t)
	defer suite.teardown()
	
	activationRequest := map[string]string{
		"license_key": "ISX1Y-LOAD-12345-TESTS-67890",
		"email":       "load.test@example.com",
	}
	
	requestBody, _ := json.Marshal(activationRequest)
	
	for _, concurrency := range []int{1, 10, 50} { // Lower concurrency for activation tests
		t.Run(fmt.Sprintf("activation_concurrency_%d", concurrency), func(t *testing.T) {
			results := runLoadTest(t, suite.server.URL+"/api/license/activate", "POST", requestBody, concurrency, 10*time.Second)
			
			t.Logf("Activation Load Test - Concurrency %d", concurrency)
			t.Logf("Requests: %d, Success: %d, Errors: %d", 
				results.TotalRequests, results.SuccessfulRequests, results.ErrorCount)
			t.Logf("Throughput: %.2f req/s, Avg Latency: %v", 
				results.Throughput, results.AverageLatency)
			
			// More lenient assertions for activation endpoint
			assert.Greater(t, results.TotalRequests, int64(0), "Should have made requests")
			// Activation may have higher error rates due to validation, so we're more lenient
			assert.Less(t, results.ErrorCount, results.TotalRequests, "Not all requests should fail")
		})
	}
}

// TestMemoryUsageUnderLoad tests memory usage patterns under load
func TestMemoryUsageUnderLoad(t *testing.T) {
	if testing.Short() {
		t.Skip("Skipping memory test in short mode")
	}
	
	suite := setupPerformanceTest(t)
	defer suite.teardown()
	
	// Measure initial memory
	runtime.GC()
	var initialMem runtime.MemStats
	runtime.ReadMemStats(&initialMem)
	
	t.Logf("Initial memory - Alloc: %d KB, Sys: %d KB", initialMem.Alloc/1024, initialMem.Sys/1024)
	
	// Run sustained load
	concurrency := 50
	duration := 30 * time.Second
	
	results := runLoadTest(t, suite.server.URL+"/api/license/status", "GET", nil, concurrency, duration)
	
	// Measure final memory
	runtime.GC()
	var finalMem runtime.MemStats
	runtime.ReadMemStats(&finalMem)
	
	t.Logf("Final memory - Alloc: %d KB, Sys: %d KB", finalMem.Alloc/1024, finalMem.Sys/1024)
	t.Logf("Memory growth - Alloc: %d KB, Sys: %d KB", 
		int64(finalMem.Alloc-initialMem.Alloc)/1024, 
		int64(finalMem.Sys-initialMem.Sys)/1024)
	
	// Performance results
	t.Logf("Load test results - Requests: %d, Throughput: %.2f req/s", 
		results.TotalRequests, results.Throughput)
	
	// Memory assertions - should not grow excessively
	memoryGrowthMB := int64(finalMem.Alloc-initialMem.Alloc) / (1024 * 1024)
	assert.Less(t, memoryGrowthMB, int64(100), "Memory growth should be less than 100MB")
	
	// Performance assertions
	assert.Greater(t, results.Throughput, float64(100), "Should maintain reasonable throughput")
}

// TestConcurrentActivationAttempts tests behavior under concurrent activation load
func TestConcurrentActivationAttempts(t *testing.T) {
	suite := setupPerformanceTest(t)
	defer suite.teardown()
	
	numWorkers := 20
	numRequestsPerWorker := 10
	
	var wg sync.WaitGroup
	var successCount int64
	var errorCount int64
	var totalLatency int64
	
	activationRequest := map[string]string{
		"license_key": "ISX1Y-CONC-12345-TESTS-67890",
		"email":       "concurrent@test.com",
	}
	requestBody, _ := json.Marshal(activationRequest)
	
	start := time.Now()
	
	wg.Add(numWorkers)
	for i := 0; i < numWorkers; i++ {
		go func(workerID int) {
			defer wg.Done()
			
			for j := 0; j < numRequestsPerWorker; j++ {
				requestStart := time.Now()
				
				resp, err := http.Post(
					suite.server.URL+"/api/license/activate",
					"application/json",
					bytes.NewReader(requestBody),
				)
				
				latency := time.Since(requestStart)
				atomic.AddInt64(&totalLatency, int64(latency))
				
				if err != nil {
					atomic.AddInt64(&errorCount, 1)
					t.Logf("Worker %d request %d failed: %v", workerID, j, err)
					continue
				}
				
				resp.Body.Close()
				
				if resp.StatusCode >= 200 && resp.StatusCode < 500 {
					atomic.AddInt64(&successCount, 1)
				} else {
					atomic.AddInt64(&errorCount, 1)
				}
			}
		}(i)
	}
	
	wg.Wait()
	totalDuration := time.Since(start)
	
	totalRequests := int64(numWorkers * numRequestsPerWorker)
	avgLatency := time.Duration(totalLatency / totalRequests)
	throughput := float64(totalRequests) / totalDuration.Seconds()
	
	t.Logf("Concurrent activation test completed:")
	t.Logf("Total requests: %d, Success: %d, Errors: %d", totalRequests, successCount, errorCount)
	t.Logf("Duration: %v, Throughput: %.2f req/s", totalDuration, throughput)
	t.Logf("Average latency: %v", avgLatency)
	
	// Assertions
	assert.Greater(t, successCount, int64(0), "Should have some successful requests")
	assert.Less(t, errorCount, totalRequests, "Not all requests should fail")
	assert.Less(t, avgLatency, 5*time.Second, "Average latency should be reasonable")
}

// TestDatabaseConnectionPool tests performance with simulated database load
func TestDatabaseConnectionPool(t *testing.T) {
	// This would test database connection pooling if using a database
	// For file-based license storage, we test file system performance
	
	suite := setupPerformanceTest(t)
	defer suite.teardown()
	
	concurrency := 100
	duration := 10 * time.Second
	
	// Test mixed read/write operations
	var wg sync.WaitGroup
	var operations int64
	var errors int64
	
	ctx, cancel := context.WithTimeout(context.Background(), duration)
	defer cancel()
	
	// Start workers
	wg.Add(concurrency)
	for i := 0; i < concurrency; i++ {
		go func(workerID int) {
			defer wg.Done()
			
			for {
				select {
				case <-ctx.Done():
					return
				default:
					// Alternate between read and write operations
					if workerID%2 == 0 {
						// Read operation
						_, err := suite.service.GetStatus(context.Background())
						if err != nil {
							atomic.AddInt64(&errors, 1)
						}
					} else {
						// Validation operation
						_, err := suite.service.ValidateWithContext(context.Background())
						if err != nil {
							// Validation errors are expected for test scenarios
						}
					}
					
					atomic.AddInt64(&operations, 1)
				}
			}
		}(i)
	}
	
	wg.Wait()
	
	throughput := float64(operations) / duration.Seconds()
	errorRate := float64(errors) / float64(operations) * 100
	
	t.Logf("Database simulation test - Operations: %d, Errors: %d", operations, errors)
	t.Logf("Throughput: %.2f ops/s, Error rate: %.2f%%", throughput, errorRate)
	
	assert.Greater(t, operations, int64(1000), "Should perform substantial number of operations")
	assert.Less(t, errorRate, 5.0, "Error rate should be low")
}

// LoadTestResults contains results from load testing
type LoadTestResults struct {
	TotalRequests      int64
	SuccessfulRequests int64
	ErrorCount         int64
	Throughput         float64
	AverageLatency     time.Duration
	P95Latency         time.Duration
	MinLatency         time.Duration
	MaxLatency         time.Duration
}

// runLoadTest executes a load test and returns performance metrics
func runLoadTest(t *testing.T, url, method string, body []byte, concurrency int, duration time.Duration) LoadTestResults {
	var wg sync.WaitGroup
	var totalRequests int64
	var successfulRequests int64
	var errorCount int64
	
	latencies := make([]time.Duration, 0, 10000)
	var latencyMutex sync.Mutex
	
	ctx, cancel := context.WithTimeout(context.Background(), duration)
	defer cancel()
	
	start := time.Now()
	
	// Start workers
	wg.Add(concurrency)
	for i := 0; i < concurrency; i++ {
		go func() {
			defer wg.Done()
			
			client := &http.Client{
				Timeout: 30 * time.Second,
			}
			
			for {
				select {
				case <-ctx.Done():
					return
				default:
					requestStart := time.Now()
					
					var resp *http.Response
					var err error
					
					if method == "GET" {
						resp, err = client.Get(url)
					} else if method == "POST" {
						resp, err = client.Post(url, "application/json", bytes.NewReader(body))
					}
					
					latency := time.Since(requestStart)
					
					// Record latency
					latencyMutex.Lock()
					if len(latencies) < cap(latencies) {
						latencies = append(latencies, latency)
					}
					latencyMutex.Unlock()
					
					atomic.AddInt64(&totalRequests, 1)
					
					if err != nil {
						atomic.AddInt64(&errorCount, 1)
						continue
					}
					
					if resp != nil {
						resp.Body.Close()
						if resp.StatusCode >= 200 && resp.StatusCode < 400 {
							atomic.AddInt64(&successfulRequests, 1)
						} else {
							atomic.AddInt64(&errorCount, 1)
						}
					}
				}
			}
		}()
	}
	
	wg.Wait()
	actualDuration := time.Since(start)
	
	// Calculate metrics
	throughput := float64(totalRequests) / actualDuration.Seconds()
	
	var avgLatency, p95Latency, minLatency, maxLatency time.Duration
	if len(latencies) > 0 {
		// Sort latencies for percentile calculation
		for i := 0; i < len(latencies)-1; i++ {
			for j := 0; j < len(latencies)-i-1; j++ {
				if latencies[j] > latencies[j+1] {
					latencies[j], latencies[j+1] = latencies[j+1], latencies[j]
				}
			}
		}
		
		var totalLatency time.Duration
		for _, lat := range latencies {
			totalLatency += lat
		}
		avgLatency = totalLatency / time.Duration(len(latencies))
		
		p95Index := int(float64(len(latencies)) * 0.95)
		if p95Index >= len(latencies) {
			p95Index = len(latencies) - 1
		}
		p95Latency = latencies[p95Index]
		
		minLatency = latencies[0]
		maxLatency = latencies[len(latencies)-1]
	}
	
	return LoadTestResults{
		TotalRequests:      totalRequests,
		SuccessfulRequests: successfulRequests,
		ErrorCount:         errorCount,
		Throughput:         throughput,
		AverageLatency:     avgLatency,
		P95Latency:         p95Latency,
		MinLatency:         minLatency,
		MaxLatency:         maxLatency,
	}
}

// BenchmarkMemoryAllocations benchmarks memory allocations
func BenchmarkMemoryAllocations(b *testing.B) {
	suite := setupBenchmark(b)
	defer suite.teardown()
	
	ctx := context.Background()
	
	b.ReportAllocs()
	b.ResetTimer()
	
	for i := 0; i < b.N; i++ {
		// Test various operations for memory allocation patterns
		suite.service.GetStatus(ctx)
		suite.service.ValidateWithContext(ctx)
		suite.service.GetDetailedStatus(ctx)
	}
}

// TestResourceCleanup tests that resources are properly cleaned up
func TestResourceCleanup(t *testing.T) {
	// Test multiple setup/teardown cycles
	for i := 0; i < 10; i++ {
		suite := setupPerformanceTest(t)
		
		// Perform some operations
		ctx := context.Background()
		suite.service.GetStatus(ctx)
		suite.service.ValidateWithContext(ctx)
		
		// Cleanup
		suite.teardown()
	}
	
	// Force garbage collection and check for resource leaks
	runtime.GC()
	runtime.GC() // Second GC to ensure cleanup
	
	var m runtime.MemStats
	runtime.ReadMemStats(&m)
	
	t.Logf("Final memory after cleanup cycles - Alloc: %d KB, NumGC: %d", 
		m.Alloc/1024, m.NumGC)
	
	// Basic assertion that we haven't leaked massive amounts of memory
	assert.Less(t, m.Alloc, uint64(50*1024*1024), "Should not have leaked more than 50MB")
}